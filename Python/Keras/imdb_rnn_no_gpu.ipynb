{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB: recursive neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the review vary in length, and we prefer to limit the computation time, we will base the classification on the first 100 features of each input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_length = 100\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=feature_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=feature_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, to limit computation time, we restrict the number of features to 5000.  This means we map all features with an index of 20000 or more to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_features = 5_000\n",
    "x_train[x_train > nr_features - 1] = 0\n",
    "x_test[x_test > nr_features - 1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training and test input are 2D arrays. We split the training set into a subset for actual training, and one for validation.  First we seed the random number generator to ensure reproducibility. In this case, we will use part of the 25000 test examples as valiation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required imports & model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, to limit training times, we restrict ourselfs to using a limited number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(nr_features, 64, mask_zero=True,\n",
    "                    input_length=feature_length))\n",
    "model.add(GRU(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 64)           320000    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 344,833\n",
      "Trainable params: 344,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 6250 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 71s 3ms/step - loss: 0.4535 - acc: 0.7750 - val_loss: 0.3570 - val_acc: 0.8414\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 69s 3ms/step - loss: 0.3060 - acc: 0.8751 - val_loss: 0.3766 - val_acc: 0.8317\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 69s 3ms/step - loss: 0.2580 - acc: 0.8977 - val_loss: 0.3574 - val_acc: 0.8493\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 69s 3ms/step - loss: 0.2153 - acc: 0.9182 - val_loss: 0.4019 - val_acc: 0.8405\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 70s 3ms/step - loss: 0.1744 - acc: 0.9365 - val_loss: 0.4157 - val_acc: 0.8414\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 69s 3ms/step - loss: 0.1435 - acc: 0.9491 - val_loss: 0.5269 - val_acc: 0.8302\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 69s 3ms/step - loss: 0.1171 - acc: 0.9593 - val_loss: 0.5158 - val_acc: 0.8338\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 69s 3ms/step - loss: 0.0932 - acc: 0.9680 - val_loss: 0.6397 - val_acc: 0.8269\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 70s 3ms/step - loss: 0.0814 - acc: 0.9727 - val_loss: 0.6510 - val_acc: 0.8309\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 71s 3ms/step - loss: 0.0655 - acc: 0.9795 - val_loss: 0.7462 - val_acc: 0.8310\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=10,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy is much better than the validation accurcy, so the model is likely heavily overtrained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18750/18750 [==============================] - 11s 565us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6996061566193899, 0.8343466666857402]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required imports & model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, to limit training times, we restrict ourselfs to using a limited number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(nr_features, 64, mask_zero=True,\n",
    "                    input_length=feature_length))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 64)           320000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 353,089\n",
      "Trainable params: 353,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 6250 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 98s 4ms/step - loss: 0.4387 - acc: 0.7948 - val_loss: 0.3717 - val_acc: 0.8365\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 97s 4ms/step - loss: 0.3045 - acc: 0.8735 - val_loss: 0.3505 - val_acc: 0.8520\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 96s 4ms/step - loss: 0.2594 - acc: 0.8978 - val_loss: 0.3841 - val_acc: 0.8424\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 96s 4ms/step - loss: 0.2194 - acc: 0.9138 - val_loss: 0.4189 - val_acc: 0.8370\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 96s 4ms/step - loss: 0.1832 - acc: 0.9308 - val_loss: 0.4222 - val_acc: 0.8358\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 98s 4ms/step - loss: 0.1572 - acc: 0.9404 - val_loss: 0.4799 - val_acc: 0.8307\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 95s 4ms/step - loss: 0.1329 - acc: 0.9524 - val_loss: 0.5651 - val_acc: 0.8301\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 97s 4ms/step - loss: 0.1279 - acc: 0.9531 - val_loss: 0.6416 - val_acc: 0.8243\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 97s 4ms/step - loss: 0.1064 - acc: 0.9606 - val_loss: 0.5738 - val_acc: 0.8293\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 97s 4ms/step - loss: 0.0975 - acc: 0.9660 - val_loss: 0.6127 - val_acc: 0.8170\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=10,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy is much better than the validation accurcy, so the model is likely heavily overtrained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18750/18750 [==============================] - 12s 637us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5942397989654541, 0.822453333307902]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
