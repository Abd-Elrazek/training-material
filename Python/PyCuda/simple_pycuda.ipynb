{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCUDA: querying devices and simple kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on the book *Hands on GPU programming with Python and CUDA* by Brian Tuomanen (ISBN 978-1-78899-391-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying device information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the CUDA driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as drv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drv.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the number of available devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drv.Device.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, assign the device to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = drv.Device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the name of the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-SXM2-16GB'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the CUDA compute capability of this device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.compute_capability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the total memory of the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.8992919921875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.total_memory()/1024**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and initialize the driver if not already done. Import `gpuarray` to get data into the device memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "from pycuda import gpuarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy array in the host memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_data = np.array([1.1, 2.2, 3.3, 4.4], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer the array to device memory and perform a simple computation on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_data = gpuarray.to_gpu(host_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_data_new = 3.14*gpu_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer the array from device memory to host memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_data_new = gpu_data_new.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.4540002,  6.9080005, 10.362    , 13.816001 ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure performance. Create a host array of 10 million elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_data = np.random.uniform(size=10_000_000).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time a simple computation, including transferring data to and from device memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.6 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "gpu_data = gpuarray.to_gpu(host_data)\n",
    "gpu_data_new = gpu_data*np.float32(2.0)\n",
    "host_data_new = gpu_data_new.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the duration of the actual computation, so without data transfer overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_data = gpuarray.to_gpu(host_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "gpu_data_new = gpu_data*np.float32(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.36 ms ± 323 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.float32(2.0)*host_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it would in theory be possible to perform computation using this style of programming, this would be very inefficient.  Computations on a GPGPU are typically coded using kernel functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementwise kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "from pycuda import gpuarray\n",
    "from pycuda.elementwise import ElementwiseKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute the Mandelbrot set.  First, initialize the initial values for $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val, max_val, nr_points = -1.8, 1.8, 2**14\n",
    "lattice = (np.linspace(min_val, max_val, nr_points, dtype=np.complex64).reshape((1, -1)) +\n",
    "           np.complex64(1.0j)*np.linspace(min_val, max_val, nr_points, dtype=np.complex64).reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer the data to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_gpu = gpuarray.to_gpu(lattice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty array of the same shape on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_gpu = gpuarray.empty(lattice.shape, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the CUDA elementwise kernel.\n",
    "  * The first argument represents the parameters of the kernel function.  Note that 2D numpy arrays will be passed as 1D C arrays to the kernel function.\n",
    "  * The second argument is the source code for the kernel function.  Note that an index `i` for the arrays passed as arguments is automatically generated.\n",
    "  * The third argument is the name of the kernel function.\n",
    "  \n",
    "We can use the C types, exept for complex numbers, which should be typed as `pycuda::complex<float>` for single precision floating point numbers.\n",
    "\n",
    "`int` on the device is 32-bit, so the Python 3 integer should be converted into a numpy 32-bit integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ElementwiseKernel(\n",
    "    'pycuda::complex<float> *lattice, float *graph, int max_iters, float upper_bound',\n",
    "    '''\n",
    "    graph[i] = 1.0f;\n",
    "    pycuda::complex<float> c = lattice[i];\n",
    "    pycuda::complex<float> z(0.0f, 0.0f);\n",
    "    for (int j = 0; j < max_iters; ++j) {\n",
    "        z = z*z + c;\n",
    "        if (abs(z) > upper_bound) {\n",
    "            graph[i] = 0.0f;\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    ''',\n",
    "    'madelbrot_kernel'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the kernel function, retrieve and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel(lattice_gpu, graph_gpu, np.int32(255), np.float32(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_gpu.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(graph);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "from pycuda import gpuarray\n",
    "from pycuda.scan  import InclusiveScanKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a scan on an array, computing the running sum of its elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  4,  7, 10, 13, 16, 19, 22, 25, 28], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_data = np.arange(1, 30, 3, dtype=np.int32)\n",
    "host_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_data = gpuarray.to_gpu(host_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and run the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = InclusiveScanKernel(np.int32, \"a + b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   5,  12,  22,  35,  51,  70,  92, 117, 145], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel(gpu_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the computation has been done in place, the result is just returned forconvenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   5,  12,  22,  35,  51,  70,  92, 117, 145], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_data.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "from pycuda import gpuarray\n",
    "from pycuda.reduction import ReductionKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_data = np.random.normal(size=100_000_000).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_data = gpuarray.to_gpu(host_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a kernel that computes the maximum of the array.  This can be done by an elementwise reduction with the first array element as the neutral element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_kernel = ReductionKernel(np.float32,\n",
    "                             neutral=str(host_data[0]),\n",
    "                             reduce_expr='a > b ? a : b',\n",
    "                             arguments='float *in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(5.7034426, dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_kernel(gpu_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is identical when computed on the CPU using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7034426"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar kernel can be defined for the minimum of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_kernel = ReductionKernel(np.float32,\n",
    "                             neutral='0.0',\n",
    "                             reduce_expr='a > b ? b : a',\n",
    "                             arguments='float *in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-5.556572, dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_kernel(gpu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.556572"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_data.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result as returned as a numpy array with a single element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ReductionKernel` is in fact more powerful, it can be used to implement a map-reduce operation.  We can implement the scalar product of two vectors easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_kernel = ReductionKernel(np.float32,\n",
    "                             neutral='0.0',\n",
    "                             reduce_expr='a + b',\n",
    "                             map_expr='v1[i]*v2[i]',\n",
    "                             arguments='float *v1, float *v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two vectors on the host system, and transfer to the device memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_v1 = np.random.uniform(size=10_000_000).astype(np.float32)\n",
    "host_v2 = np.random.uniform(size=10_000_000).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_v1 = gpuarray.to_gpu(host_v1)\n",
    "gpu_v2 = gpuarray.to_gpu(host_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2499344.8, dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_kernel(gpu_v1, gpu_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is nearly the same on the CPU, except for the least signicant digit due to rounding differences consistent with single precision arithmetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2499345.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_v1@host_v2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
